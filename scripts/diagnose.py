"""
è¯Šæ–­è„šæœ¬ï¼šæ£€æŸ¥æ¨¡å‹å’Œæ•°æ®çš„å„ä¸ªç¯èŠ‚
"""
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import numpy as np
from configs.config import BEVConfig as cfg
from data.dataset import BEVMultiTaskDataset
from models.detector import WBEVFusionNet

def diagnose():
    print("="*60)
    print("ğŸ”¬ W-BEVFusion è¯Šæ–­è„šæœ¬")
    print("="*60)
    
    # 1. æ£€æŸ¥æ•°æ®é›†
    print("\nğŸ“Š æ­¥éª¤ 1: æ£€æŸ¥æ•°æ®é›†")
    print("-"*60)
    dataset = BEVMultiTaskDataset(data_root='/root/autodl-tmp/FOD/data', split='val')
    print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)} ä¸ªæ ·æœ¬")
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬
    img, points, targets = dataset[0]
    print(f"âœ… å›¾åƒå½¢çŠ¶: {img.shape}")
    print(f"âœ… ç‚¹äº‘å½¢çŠ¶: {points.shape}")
    print(f"âœ… GT Heatmap å½¢çŠ¶: {targets['hm'].shape}")
    print(f"âœ… GT Rail Mask å½¢çŠ¶: {targets['mask'].shape}")
    print(f"âœ… GT Boxes æ•°é‡: {len(targets['boxes'])}")
    
    # æ£€æŸ¥ GT ç»Ÿè®¡
    hm_max = targets['hm'].max().item()
    hm_pos = (targets['hm'] > 0.1).sum().item()
    mask_ratio = (targets['mask'] > 0.5).float().mean().item()
    
    print(f"\nğŸ“ˆ GT ç»Ÿè®¡:")
    print(f"   - Heatmap æœ€å¤§å€¼: {hm_max:.4f}")
    print(f"   - Heatmap æ­£æ ·æœ¬æ•°: {hm_pos}")
    print(f"   - Rail Mask å æ¯”: {mask_ratio*100:.2f}%")
    print(f"   - ç›®æ ‡æ¡†æ•°é‡: {len(targets['boxes'])}")
    
    if hm_pos == 0:
        print("   âš ï¸ è­¦å‘Š: ç¬¬ä¸€ä¸ªæ ·æœ¬æ²¡æœ‰ç›®æ ‡ï¼")
    if mask_ratio < 0.01:
        print("   âš ï¸ è­¦å‘Š: Rail Mask å‡ ä¹ä¸ºç©ºï¼")
    
    # 2. æ£€æŸ¥æ¨¡å‹
    print("\nğŸ¤– æ­¥éª¤ 2: æ£€æŸ¥æ¨¡å‹")
    print("-"*60)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = WBEVFusionNet().to(device)
    print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {device}")
    
    # æ£€æŸ¥å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"âœ… æ€»å‚æ•°: {total_params:,}")
    print(f"âœ… å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # 3. æ£€æŸ¥å‰å‘ä¼ æ’­
    print("\nğŸ”„ æ­¥éª¤ 3: æ£€æŸ¥å‰å‘ä¼ æ’­")
    print("-"*60)
    
    images = img.unsqueeze(0).to(device)
    points_list = [points.to(device)]
    
    model.eval()
    with torch.no_grad():
        outputs = model(images, points_list)
    
    print(f"âœ… cls_pred å½¢çŠ¶: {outputs['cls_pred'].shape}")
    print(f"âœ… box_pred å½¢çŠ¶: {outputs['box_pred'].shape}")
    print(f"âœ… mask_pred å½¢çŠ¶: {outputs['mask_pred'].shape}")
    
    # æ£€æŸ¥è¾“å‡ºç»Ÿè®¡
    cls_mean = outputs['cls_pred'].mean().item()
    cls_std = outputs['cls_pred'].std().item()
    cls_max = outputs['cls_pred'].max().item()
    cls_min = outputs['cls_pred'].min().item()
    
    print(f"\nğŸ“Š cls_pred ç»Ÿè®¡ (logits):")
    print(f"   - å‡å€¼: {cls_mean:.4f}")
    print(f"   - æ ‡å‡†å·®: {cls_std:.4f}")
    print(f"   - æœ€å¤§å€¼: {cls_max:.4f}")
    print(f"   - æœ€å°å€¼: {cls_min:.4f}")
    
    cls_prob = torch.sigmoid(outputs['cls_pred'])
    prob_mean = cls_prob.mean().item()
    prob_max = cls_prob.max().item()
    print(f"\nğŸ“Š cls_pred ç»Ÿè®¡ (æ¦‚ç‡):")
    print(f"   - å‡å€¼: {prob_mean:.4f}")
    print(f"   - æœ€å¤§å€¼: {prob_max:.4f}")
    
    if abs(prob_mean - 0.5) < 0.05:
        print("   âš ï¸ è­¦å‘Š: æ¦‚ç‡é›†ä¸­åœ¨ 0.5 é™„è¿‘ï¼Œå¯èƒ½æ˜¯åŒé‡ sigmoid æˆ–æœªè®­ç»ƒï¼")
    
    # æ£€æŸ¥ mask_pred
    mask_mean = torch.sigmoid(outputs['mask_pred']).mean().item()
    print(f"\nğŸ“Š mask_pred ç»Ÿè®¡:")
    print(f"   - é¢„æµ‹å‡å€¼: {mask_mean:.4f}")
    
    # 4. æ£€æŸ¥æƒé‡æ–‡ä»¶
    print("\nğŸ’¾ æ­¥éª¤ 4: æ£€æŸ¥æœ€æ–°æƒé‡")
    print("-"*60)
    
    ckpt_dir = '/root/autodl-tmp/FOD/W-BEVFusion/checkpoints'
    if os.path.exists(ckpt_dir):
        import glob
        pth_files = glob.glob(os.path.join(ckpt_dir, '*.pth'))
        if pth_files:
            latest_ckpt = max(pth_files, key=os.path.getctime)
            ckpt_time = os.path.getctime(latest_ckpt)
            
            from datetime import datetime
            ckpt_datetime = datetime.fromtimestamp(ckpt_time)
            
            print(f"âœ… æœ€æ–°æƒé‡: {os.path.basename(latest_ckpt)}")
            print(f"âœ… ä¿®æ”¹æ—¶é—´: {ckpt_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # åŠ è½½æƒé‡å¹¶æ£€æŸ¥
            checkpoint = torch.load(latest_ckpt, map_location='cpu')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ optimizer stateï¼ˆè¯´æ˜æ˜¯å®Œæ•´è®­ç»ƒä¿å­˜ï¼‰
            if isinstance(checkpoint, dict) and 'optimizer_state_dict' in checkpoint:
                print("âœ… æƒé‡åŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå®Œæ•´è®­ç»ƒä¿å­˜ï¼‰")
            
            # åŠ è½½æƒé‡åˆ°æ¨¡å‹
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
            
            model.load_state_dict(state_dict, strict=False)
            print("âœ… æƒé‡å·²åŠ è½½")
            
            # é‡æ–°æ£€æŸ¥è¾“å‡º
            model.eval()
            with torch.no_grad():
                outputs_trained = model(images, points_list)
            
            cls_trained_mean = torch.sigmoid(outputs_trained['cls_pred']).mean().item()
            mask_trained_mean = torch.sigmoid(outputs_trained['mask_pred']).mean().item()
            
            print(f"\nğŸ“Š åŠ è½½æƒé‡åçš„è¾“å‡º:")
            print(f"   - cls_pred å‡å€¼: {cls_trained_mean:.4f}")
            print(f"   - mask_pred å‡å€¼: {mask_trained_mean:.4f}")
            
            if abs(cls_trained_mean - 0.5) < 0.05:
                print("   âŒ ä¸¥é‡é—®é¢˜: åˆ†ç±»è¾“å‡ºä»ç„¶æ¥è¿‘ 0.5ï¼Œæ¨¡å‹æœªå­¦ä¹ ï¼")
            else:
                print("   âœ… åˆ†ç±»è¾“å‡ºæ­£å¸¸")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶")
    
    # 5. æ€»ç»“
    print("\n"+"="*60)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
    print("="*60)
    
    issues = []
    if hm_pos == 0:
        issues.append("âŒ æ•°æ®é›†ä¸­æ²¡æœ‰æ­£æ ·æœ¬æ ‡æ³¨")
    if mask_ratio < 0.01:
        issues.append("âŒ Rail Mask å‡ ä¹ä¸ºç©º")
    if abs(prob_mean - 0.5) < 0.05:
        issues.append("âŒ æ¨¡å‹è¾“å‡ºæ¥è¿‘éšæœºï¼ˆå¯èƒ½æ˜¯åŒé‡sigmoidæˆ–æœªè®­ç»ƒï¼‰")
    if 'cls_trained_mean' in locals() and abs(cls_trained_mean - 0.5) < 0.05:
        issues.append("âŒ åŠ è½½æƒé‡åä»ç„¶è¾“å‡ºéšæœºå€¼")
    
    if issues:
        print("âš ï¸ å‘ç°ä»¥ä¸‹é—®é¢˜:")
        for issue in issues:
            print(f"   {issue}")
    else:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
    
    print("\nğŸ’¡ å»ºè®®:")
    if len(issues) == 0:
        print("   - æ¨¡å‹å’Œæ•°æ®çœ‹èµ·æ¥æ­£å¸¸ï¼Œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´è®­ç»ƒ")
    elif "æ•°æ®é›†ä¸­æ²¡æœ‰æ­£æ ·æœ¬æ ‡æ³¨" in str(issues):
        print("   - æ£€æŸ¥æ•°æ®é›†æ ‡æ³¨è§£æé€»è¾‘ (data/dataset.py)")
        print("   - ç¡®è®¤ raillabel è§£ææ˜¯å¦æ­£ç¡®")
    elif "æ¨¡å‹è¾“å‡ºæ¥è¿‘éšæœº" in str(issues):
        print("   - æ£€æŸ¥è®­ç»ƒæ—¥å¿—ä¸­ Cls Loss æ˜¯å¦ä¸º 0.0000")
        print("   - å¦‚æœæ˜¯ï¼Œè¯´æ˜è®­ç»ƒä½¿ç”¨çš„æ˜¯æ—§ä»£ç ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
    
    print("\n"+"="*60)

if __name__ == "__main__":
    diagnose()
